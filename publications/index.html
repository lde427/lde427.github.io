<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Dongeon Lee | publications</title>
  <meta name="description" content="This is the personal website of Dongeon Lee">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Dongeon Lee</span></a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
            
            
              <li class="nav-item navbar-active font-weight-bold">
                  <a class="nav-link" href="/publications/">
                    publications
                    
                      <span class="sr-only">(current)</span>
                    
                  </a>
              </li>

          
            
        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>publications</h1>
  <h6><nobr><em>*</em></nobr> denotes equal contribution and joint lead authorship.</h6>


<p><br /></p>

<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2024</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="https://arxiv.org/" target="_blank">
          arXiv
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="VPD" class="col p-0">
      <h5 class="title mb-0">Visual Program Distillation: Distilling Tools and Programmatic Reasoning into Vision-Language Models.</h5>
      <div class="author">
        
          
          
            
              
                
                  <nobr><a href="https://yushi-hu.github.io/" target="_blank">Yushi Hu</a>,</nobr>
                
              
            
          
        
          
          
            
              
                <nobr><em>Otilia Stretcu</em>,</nobr>
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www2.cs.uic.edu/~clu/" target="_blank">Chun-Ta Lu</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/krishnamurthy-viswanathan-14b65a42/" target="_blank">Krishnamurthy Viswanathan</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/kenjihata/" target="_blank">Kenji Hata</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/enming-luo-a1018614/" target="_blank">Enming Luo</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://ranjaykrishna.com/index.html" target="_blank">Ranjay Krishna</a>,</nobr>
                
              
            
          
        
          
          
            
              and
              
                
                  <nobr><a href="https://scholar.google.com/citations?user=pyzFbV0AAAAJ&amp;hl=en" target="_blank">Ariel Fuxman</a>.</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Proceedings of the Forty-First IEEE/CVF Conference on Computer Vision and Pattern Recognition. Oral presentation
          
          
            2024.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#VPD-abstract" role="button" aria-expanded="false" aria-controls="VPD-abstract">Abstract</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/2312.03052" target="_blank">arXiv</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://visual-program-distillation.github.io/" target="_blank">Website</a>
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.youtube.com/watch?v=mofEOquxPjQ&amp;ab_channel=YushiHu" target="_blank">Video</a>

          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/obfuscation_benchmark/obfuscation_benchmark.pdf" target="_blank">PDF</a>
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="VPD-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Solving complex visual tasks such as "Who invented the musical instrument on the right?" involves a composition of skills: understanding space, recognizing instruments, and also retrieving prior knowledge. Recent work shows promise by decomposing such tasks using a large language model (LLM) into an executable program that invokes specialized vision models. However, generated programs are error-prone: they omit necessary steps, include spurious ones, and are unable to recover when the specialized models give incorrect outputs. Moreover, they require loading multiple models, incurring high latency and computation costs. We propose Visual Program Distillation (VPD), an instruction tuning framework that produces a vision-language model (VLM) capable of solving complex visual tasks with a single forward pass. VPD distills the reasoning ability of LLMs by using them to sample multiple candidate programs, which are then executed and verified to identify a correct one. It translates each correct program into a language description of the reasoning steps, which are then distilled into a VLM. Extensive experiments show that VPD improves the VLM’s ability to count, understand spatial relations, and reason compositionally. Our VPD-trained PaLI-X outperforms all prior VLMs, achieving state-of-the-art performance across complex vision tasks, including MMBench, OK-VQA, A-OKVQA, TallyQA, POPE, and Hateful Memes. An evaluation with human annotators also confirms that VPD improves model response factuality and consistency. Finally, experiments on content moderation demonstrate that VPD is also helpful for adaptation to real-world applications with limited data.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>

    
<div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2024</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography"><li><div class="row m-0 mt-3 p-0">
  <div class="col-sm-1 p-0 abbr">
    
      
        <a class="badge font-weight-bold light-green darken-1 align-middle" style="width: 65px;" href="http://www.nips.cc/" target="_blank">
          NeurIPS
        </a>
      
    
  </div>
  <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
    
    <div id="obfuscation_benchmark" class="col p-0">
      <h5 class="title mb-0">Benchmarking Robustness to Adversarial Image Obfuscations.</h5>
      <div class="author">
        
          
          
            
              
                
                  <nobr><a href="https://uk.linkedin.com/in/florian-stimberg-71773576" target="_blank">Florian Stimberg</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://projects.ayanc.org/" target="_blank">Ayan Chakrabarti</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www2.cs.uic.edu/~clu/" target="_blank">Chun-Ta Lu</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.hazimeh.com/" target="_blank">Hussein Hazimeh</a>,</nobr>
                
              
            
          
        
          
          
            
              
                <nobr><em>Otilia Stretcu</em>,</nobr>
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/wayneqiao/" target="_blank">Wei Qiao</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr>Yintao Liu,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/emkaya/" target="_blank">Merve Kaya</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://sites.google.com/site/cyrusrashtchian/home" target="_blank">Cyrus Rashtchian</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://scholar.google.com/citations?user=pyzFbV0AAAAJ&amp;hl=en" target="_blank">Ariel Fuxman</a>,</nobr>
                
              
            
          
        
          
          
            
              
                
                  <nobr><a href="https://www.linkedin.com/in/mehmettek" target="_blank">Mehmet Tek</a>,</nobr>
                
              
            
          
        
          
          
            
              and
              
                
                  <nobr><a href="https://scholar.google.com/citations?user=7wclGnQAAAAJ&amp;hl=en" target="_blank">Sven Gowal</a>.</nobr>
                
              
            
          
        
      </div>

      <div>
        <p class="periodical font-italic">
          
            In Proceedings of the Thirty-Seventh Conference on Neural Information Processing Systems
          
          
            2023.
          
        </p>
      </div>
    
      <div class="col p-0">
        
          <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#obfuscation_benchmark-abstract" role="button" aria-expanded="false" aria-controls="obfuscation_benchmark-abstract">Abstract</a>
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="/assets/pdf/obfuscation_benchmark/obfuscation_benchmark.pdf" target="_blank">PDF</a>
        
        
        
        
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="https://github.com/google-deepmind/image_obfuscation_benchmark" target="_blank">Code</a>
        
        
          <a class="badge grey waves-effect font-weight-light mr-1" href="http://arxiv.org/abs/2301.12993" target="_blank">arXiv</a>
        
        
        
      </div>
    
      
      <div class="col mt-2 p-0">
        <div id="obfuscation_benchmark-abstract" class="collapse">
          <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
            Automated content filtering and moderation is an important tool that allows online platforms to build striving user communities that facilitate cooperation and prevent abuse. Unfortunately, resourceful actors try to bypass automated filters in a bid to post content that violate platform policies and codes of conduct. To reach this goal, these malicious actors may obfuscate policy violating images (e.g. overlay harmful images by carefully selected benign images or visual patterns) to prevent machine learning models from reaching the correct decision. In this paper, we invite researchers to tackle this specific issue and present a new image benchmark. This benchmark, based on ImageNet, simulates the type of obfuscations created by malicious actors. It goes beyond ImageNet-C and ImageNet-C¯ by proposing general, drastic, adversarial modifications that preserve the original content intent. It aims to tackle a more common adversarial threat than the one considered by Lp-norm bounded adversaries. We evaluate 33 pretrained models on the benchmark and train models with different augmentations, architectures and training methods on subsets of the obfuscations to measure generalization. We hope this benchmark will encourage researchers to test their models and methods and try to find new approaches that are more robust to these obfuscations.
          </div>
        </div>
      </div>
      
    </div>
  </div>
</div>
</li></ol>
    </div>
  </div>



  <!-- Footer -->
  <footer>
    &copy; Copyright 2024 Dongeon Lee.
    
    
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', '', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
